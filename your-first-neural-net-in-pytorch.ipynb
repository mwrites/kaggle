{"cells":[{"cell_type":"markdown","metadata":{},"source":["# This notebook __doesn't need gpu__, you should be able to run it very quickly on your macbook within 5 minutes. This step by step shows how to iterate on kaggle competitions and how to make your first neural net from scratch using basic pytorch."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dependencies = [\n","    \"kagtool\",\n","    \"scikit-learn\",\n","    \"numpy\",\n","    \"matplotlib\",\n","]\n","\n","%pip install -U {\" \".join(dependencies)}\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import gc\n","import torch\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-03T18:56:29.252231Z","iopub.status.busy":"2024-07-03T18:56:29.251624Z","iopub.status.idle":"2024-07-03T18:56:31.903102Z","shell.execute_reply":"2024-07-03T18:56:31.902134Z","shell.execute_reply.started":"2024-07-03T18:56:29.252199Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["digit-recognizer.zip: Skipping, found more recently modified local copy (use --force to force download)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>pixel0</th>\n","      <th>pixel1</th>\n","      <th>pixel2</th>\n","      <th>pixel3</th>\n","      <th>pixel4</th>\n","      <th>pixel5</th>\n","      <th>pixel6</th>\n","      <th>pixel7</th>\n","      <th>pixel8</th>\n","      <th>...</th>\n","      <th>pixel774</th>\n","      <th>pixel775</th>\n","      <th>pixel776</th>\n","      <th>pixel777</th>\n","      <th>pixel778</th>\n","      <th>pixel779</th>\n","      <th>pixel780</th>\n","      <th>pixel781</th>\n","      <th>pixel782</th>\n","      <th>pixel783</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 785 columns</p>\n","</div>"],"text/plain":["   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n","0      1       0       0       0       0       0       0       0       0   \n","1      0       0       0       0       0       0       0       0       0   \n","2      1       0       0       0       0       0       0       0       0   \n","3      4       0       0       0       0       0       0       0       0   \n","4      0       0       0       0       0       0       0       0       0   \n","\n","   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n","0       0  ...         0         0         0         0         0         0   \n","1       0  ...         0         0         0         0         0         0   \n","2       0  ...         0         0         0         0         0         0   \n","3       0  ...         0         0         0         0         0         0   \n","4       0  ...         0         0         0         0         0         0   \n","\n","   pixel780  pixel781  pixel782  pixel783  \n","0         0         0         0         0  \n","1         0         0         0         0  \n","2         0         0         0         0  \n","3         0         0         0         0  \n","4         0         0         0         0  \n","\n","[5 rows x 785 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# this cell works inside or oustide kaggle\n","from kagtool.datasets.kaggle_downloader import KaggleDownloader\n","\n","dataset_name = 'digit-recognizer'\n","\n","# add your creds if outside kaggle on a cloud machine\n","path = KaggleDownloader.build(dataset_name, username=None, key=None).load_or_fetch_kaggle_dataset()\n","df = pd.read_csv(path/'train.csv')\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# 🧑‍🍳 Preprocess"]},{"cell_type":"markdown","metadata":{},"source":["### Split"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-03T18:38:45.747696Z","iopub.status.busy":"2024-07-03T18:38:45.747317Z","iopub.status.idle":"2024-07-03T18:38:46.589279Z","shell.execute_reply":"2024-07-03T18:38:46.588348Z","shell.execute_reply.started":"2024-07-03T18:38:45.747662Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(array([1, 0, 1, ..., 7, 6, 9]), (42000, 784))"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.model_selection import train_test_split\n","\n","# Now train_df contains 80% of the data, and val_df contains 20%\n","train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","# The df contains both the labels and the pixel data\n","# Extract labels\n","x = df['label'].values\n","# Extract pixel data (images)\n","y = df.drop('label', axis=1).values\n","x, y.shape"]},{"cell_type":"markdown","metadata":{},"source":["### Prepare X And Y For training"]},{"cell_type":"markdown","metadata":{},"source":["> Note: For educational purpose we just gonna ignore the batch totally and load the whole all the samples at once"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-03T18:38:46.592356Z","iopub.status.busy":"2024-07-03T18:38:46.591778Z","iopub.status.idle":"2024-07-03T18:38:46.834669Z","shell.execute_reply":"2024-07-03T18:38:46.833671Z","shell.execute_reply.started":"2024-07-03T18:38:46.592329Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(torch.Size([33600, 784]), torch.Size([33600, 1]))"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["def extract_labels_and_images(df):\n","    x = df.drop('label', axis=1).values\n","    y = df['label'].values    \n","     # Convert to PyTorch tensors\n","    x_tensor = torch.from_numpy(x).float()\n","    y_tensor = torch.from_numpy(y).long().unsqueeze(1)\n","    \n","    return x_tensor, y_tensor\n","\n","X, Y = extract_labels_and_images(train_df)\n","val_x, val_y = extract_labels_and_images(val_df)\n","X.shape, Y.shape"]},{"cell_type":"markdown","metadata":{},"source":["> Note: usually you would want to load X and Y as batches instead of the whole dataset, but I didn't both to keep it simple here."]},{"cell_type":"markdown","metadata":{},"source":["### Checking That We Got An Image And A Label"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-03T18:38:46.837330Z","iopub.status.busy":"2024-07-03T18:38:46.836541Z","iopub.status.idle":"2024-07-03T18:38:47.029152Z","shell.execute_reply":"2024-07-03T18:38:47.028169Z","shell.execute_reply.started":"2024-07-03T18:38:46.837290Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["def np_show_img(array, title=''):\n","    if array.ndim == 1:  # If rank 1, reshape to 2D\n","        array = array.reshape(28, 28)\n","    plt.imshow(array, cmap='gray')\n","    plt.axis('off')\n","    plt.title(title, fontsize=14)\n","    plt.show()\n","\n","np_show_img(X[0], title=f'Label: {Y[0].item()}')"]},{"cell_type":"markdown","metadata":{},"source":["# 🧮 Model"]},{"cell_type":"markdown","metadata":{},"source":["### Your First Multi-Layer-Perceptron (MLP)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-03T18:38:47.030804Z","iopub.status.busy":"2024-07-03T18:38:47.030438Z","iopub.status.idle":"2024-07-03T18:38:47.038368Z","shell.execute_reply":"2024-07-03T18:38:47.037298Z","shell.execute_reply.started":"2024-07-03T18:38:47.030771Z"},"trusted":true},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(MLP, self).__init__()\n","        self.layer1 = nn.Linear(input_size, hidden_size)\n","        self.layer2 = nn.Linear(hidden_size, output_size)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.relu(self.layer1(x))\n","        x = self.layer2(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["### Defining Shapes"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-03T18:38:47.039869Z","iopub.status.busy":"2024-07-03T18:38:47.039563Z","iopub.status.idle":"2024-07-03T18:38:47.056161Z","shell.execute_reply":"2024-07-03T18:38:47.055123Z","shell.execute_reply.started":"2024-07-03T18:38:47.039836Z"},"trusted":true},"outputs":[{"data":{"text/plain":["MLP(\n","  (layer1): Linear(in_features=784, out_features=32, bias=True)\n","  (layer2): Linear(in_features=32, out_features=10, bias=True)\n","  (relu): ReLU()\n",")"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["n_input = X.shape[-1] # 784 px\n","n_hidden = 32 # number of neurons in the hidden layer\n","n_output = 10 # number of output classes 10 digits\n","\n","model = MLP(n_input, n_hidden, n_output)\n","model"]},{"cell_type":"markdown","metadata":{},"source":["### Your First Prediction"]},{"cell_type":"markdown","metadata":{},"source":["Trying to predict 33600 images"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-03T18:38:47.057825Z","iopub.status.busy":"2024-07-03T18:38:47.057511Z","iopub.status.idle":"2024-07-03T18:38:47.110122Z","shell.execute_reply":"2024-07-03T18:38:47.109209Z","shell.execute_reply.started":"2024-07-03T18:38:47.057795Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([33600, 10])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["model(X).shape"]},{"cell_type":"markdown","metadata":{},"source":["### From Logits To Predictions"]},{"cell_type":"markdown","metadata":{},"source":["Your model outputs logits, to make sense of them we need to turn that into probabilities"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-07-03T18:38:47.111809Z","iopub.status.busy":"2024-07-03T18:38:47.111515Z","iopub.status.idle":"2024-07-03T18:38:47.118040Z","shell.execute_reply":"2024-07-03T18:38:47.117151Z","shell.execute_reply.started":"2024-07-03T18:38:47.111785Z"},"trusted":true},"outputs":[],"source":["def accuracy(logits, Y):\n","    \"\"\"\n","    Calculate the accuracy of predictions.\n","\n","    Parameters:\n","    logits  (torch.Tensor): Tensor of true labels in one-hot encoding, shape (n_samples, n_classes)\n","    Y       (torch.Tensor): Tensor of expected classes indices, shape (n_samples, 1)\n","\n","    Returns:\n","    float: Accuracy score\n","    \"\"\"\n","    # Convert one-hot encoded true labels to class indices\n","    predictions = torch.argmax(logits, dim=1)\n","    \n","    # Flatten Y to ensure it matches the shape of predictions\n","    y_pred_labels = Y.view(-1)\n","    \n","    # Compare with true labels\n","    correct_predictions = (y_pred_labels == predictions).sum().item()\n","    \n","    # Calculate accuracy\n","    accuracy = correct_predictions / logits.size(0)\n","    \n","    return accuracy"]},{"cell_type":"markdown","metadata":{},"source":["As expected the accuracy is garbage! Because we haven't tried the model yet. So let's train it."]},{"cell_type":"markdown","metadata":{},"source":["# 🏋️‍♂️ Training"]},{"cell_type":"markdown","metadata":{},"source":["### Loss Function"]},{"cell_type":"markdown","metadata":{},"source":["First we need a loss function"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-03T18:38:47.123478Z","iopub.status.busy":"2024-07-03T18:38:47.122722Z","iopub.status.idle":"2024-07-03T18:38:47.129357Z","shell.execute_reply":"2024-07-03T18:38:47.128432Z","shell.execute_reply.started":"2024-07-03T18:38:47.123447Z"},"trusted":true},"outputs":[],"source":["def loss_fn(logits, Y):\n","    # Ensure logits are of shape (batch_size, num_classes)\n","    assert logits.ndimension() == 2 and logits.size(1) == 10\n","    # Ensure Y is of shape (batch_size, 1) and then squeeze to (batch_size,)\n","    assert Y.ndimension() == 2 and Y.size(1) == 1\n","    return nn.CrossEntropyLoss()(logits, Y.squeeze())"]},{"cell_type":"markdown","metadata":{},"source":["SGD by Hand"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1 \t| Training Loss: 27.35779\t| Training Accuracy: 0.11262\t| Validation Accuracy: 0.10964\n","Epoch 2 \t| Training Loss: 6496.52930\t| Training Accuracy: 0.10440\t| Validation Accuracy: 0.10631\n","Epoch 3 \t| Training Loss: 253112.92188\t| Training Accuracy: 0.11063\t| Validation Accuracy: 0.11286\n","Epoch 4 \t| Training Loss: 232345.82812\t| Training Accuracy: 0.11101\t| Validation Accuracy: 0.11357\n","Epoch 5 \t| Training Loss: 2.28628\t| Training Accuracy: 0.11107\t| Validation Accuracy: 0.11381\n","Epoch 6 \t| Training Loss: 2.28470\t| Training Accuracy: 0.11143\t| Validation Accuracy: 0.11429\n","Epoch 7 \t| Training Loss: 2.28299\t| Training Accuracy: 0.11223\t| Validation Accuracy: 0.11476\n","Epoch 8 \t| Training Loss: 2.28028\t| Training Accuracy: 0.11241\t| Validation Accuracy: 0.11488\n","Epoch 9 \t| Training Loss: 2.27937\t| Training Accuracy: 0.11250\t| Validation Accuracy: 0.11488\n","Epoch 10 \t| Training Loss: 2.27883\t| Training Accuracy: 0.11286\t| Validation Accuracy: 0.11536\n","Epoch 11 \t| Training Loss: 2.27782\t| Training Accuracy: 0.11333\t| Validation Accuracy: 0.11583\n","Epoch 12 \t| Training Loss: 2.27657\t| Training Accuracy: 0.11396\t| Validation Accuracy: 0.11690\n","Epoch 13 \t| Training Loss: 2.27511\t| Training Accuracy: 0.11432\t| Validation Accuracy: 0.11702\n","Epoch 14 \t| Training Loss: 2.27401\t| Training Accuracy: 0.11446\t| Validation Accuracy: 0.11702\n","Epoch 15 \t| Training Loss: 2.27343\t| Training Accuracy: 0.11467\t| Validation Accuracy: 0.11762\n","Epoch 16 \t| Training Loss: 2.27272\t| Training Accuracy: 0.11470\t| Validation Accuracy: 0.11774\n","Epoch 17 \t| Training Loss: 2.27228\t| Training Accuracy: 0.11473\t| Validation Accuracy: 0.11774\n","Epoch 18 \t| Training Loss: 2.27193\t| Training Accuracy: 0.11473\t| Validation Accuracy: 0.11774\n","Epoch 19 \t| Training Loss: 2.27161\t| Training Accuracy: 0.11473\t| Validation Accuracy: 0.11762\n","Epoch 20 \t| Training Loss: 2.27134\t| Training Accuracy: 0.11473\t| Validation Accuracy: 0.11762\n"]},{"data":{"text/plain":["(2.2713379859924316, 0.11473214285714285, 0.11761904761904762)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["def train(model, X, Y, val_x, val_y, epochs, lr, print_epochs=True):\n","    for epoch in range(epochs):\n","        # Forward\n","        model.train()\n","        logits = model(X)\n","        loss = loss_fn(logits, Y)\n","        \n","        # Backward\n","        loss.backward()\n","\n","        # Update parameters\n","        with torch.no_grad():\n","            for param in model.parameters():\n","                if param.grad is not None:\n","                    param.data -= lr * param.grad\n","                    param.grad.zero_()  # Zero out the gradients after each update\n","\n","        # Evaluation\n","        model.eval()\n","        with torch.no_grad():\n","            train_acc = accuracy(model(X), Y)\n","            val_acc = accuracy(model(val_x), val_y)\n","        if print_epochs:\n","            print(f'Epoch {epoch+1} \\t| Training Loss: {loss.item():.5f}\\t| Training Accuracy: {train_acc:.5f}\\t| Validation Accuracy: {val_acc:.5f}')\n","    return loss.item(), train_acc, val_acc\n","\n","\n","torch.manual_seed(1337)\n","epochs = 20\n","lr = 0.1\n","model = MLP(n_input, n_hidden, n_output)\n","train(model, X, Y, val_x, val_y, epochs, lr)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Not Training? We Need To Normalize!"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-07-03T18:38:48.847977Z","iopub.status.busy":"2024-07-03T18:38:48.847312Z","iopub.status.idle":"2024-07-03T18:38:48.908952Z","shell.execute_reply":"2024-07-03T18:38:48.908026Z","shell.execute_reply.started":"2024-07-03T18:38:48.847919Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([  1.1017,  11.0962,  11.3166,  -2.2534,  14.9082, -19.7100,   3.8005,\n","          3.8045,  -1.5773, -16.2333], grad_fn=<SelectBackward0>)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["model = MLP(n_input, n_hidden, n_output)\n","model(X)[0]"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-07-03T18:38:48.910312Z","iopub.status.busy":"2024-07-03T18:38:48.910026Z","iopub.status.idle":"2024-07-03T18:38:48.994428Z","shell.execute_reply":"2024-07-03T18:38:48.993420Z","shell.execute_reply.started":"2024-07-03T18:38:48.910289Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([ 0.0914, -0.0368, -0.0310,  0.1434,  0.0885, -0.1545, -0.0038,  0.0733,\n","        -0.0082,  0.0474], grad_fn=<SelectBackward0>)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["model = MLP(n_input, n_hidden, n_output)\n","model(X / 255)[0]"]},{"cell_type":"markdown","metadata":{},"source":["The reason why we need to do that, is that it's easier to optimize small numbers than big ones, think about the learning rate above, even if we update the weights by the gradients, if the weights are big, they the resulting multiplications will also be big. If we visualize parameters as movements, directions towards our goal, if every movements is big, it's hard to converge."]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1 \t| Training Loss: 2.30661\t| Training Accuracy: 0.13542\t| Validation Accuracy: 0.13488\n","Epoch 2 \t| Training Loss: 2.29159\t| Training Accuracy: 0.14583\t| Validation Accuracy: 0.14583\n","Epoch 3 \t| Training Loss: 2.27656\t| Training Accuracy: 0.15435\t| Validation Accuracy: 0.15440\n","Epoch 4 \t| Training Loss: 2.26104\t| Training Accuracy: 0.16622\t| Validation Accuracy: 0.16726\n","Epoch 5 \t| Training Loss: 2.24491\t| Training Accuracy: 0.18702\t| Validation Accuracy: 0.19000\n","Epoch 6 \t| Training Loss: 2.22793\t| Training Accuracy: 0.21310\t| Validation Accuracy: 0.21536\n","Epoch 7 \t| Training Loss: 2.21000\t| Training Accuracy: 0.24024\t| Validation Accuracy: 0.24012\n","Epoch 8 \t| Training Loss: 2.19111\t| Training Accuracy: 0.27241\t| Validation Accuracy: 0.27131\n","Epoch 9 \t| Training Loss: 2.17123\t| Training Accuracy: 0.30449\t| Validation Accuracy: 0.30345\n","Epoch 10 \t| Training Loss: 2.15028\t| Training Accuracy: 0.33830\t| Validation Accuracy: 0.33583\n","Epoch 11 \t| Training Loss: 2.12842\t| Training Accuracy: 0.37265\t| Validation Accuracy: 0.37214\n","Epoch 12 \t| Training Loss: 2.10596\t| Training Accuracy: 0.40988\t| Validation Accuracy: 0.41083\n","Epoch 13 \t| Training Loss: 2.08292\t| Training Accuracy: 0.44938\t| Validation Accuracy: 0.44857\n","Epoch 14 \t| Training Loss: 2.05926\t| Training Accuracy: 0.48926\t| Validation Accuracy: 0.48655\n","Epoch 15 \t| Training Loss: 2.03498\t| Training Accuracy: 0.52411\t| Validation Accuracy: 0.52214\n","Epoch 16 \t| Training Loss: 2.01011\t| Training Accuracy: 0.55420\t| Validation Accuracy: 0.55131\n","Epoch 17 \t| Training Loss: 1.98465\t| Training Accuracy: 0.58012\t| Validation Accuracy: 0.57774\n","Epoch 18 \t| Training Loss: 1.95857\t| Training Accuracy: 0.60262\t| Validation Accuracy: 0.59988\n","Epoch 19 \t| Training Loss: 1.93192\t| Training Accuracy: 0.62268\t| Validation Accuracy: 0.62333\n","Epoch 20 \t| Training Loss: 1.90475\t| Training Accuracy: 0.64128\t| Validation Accuracy: 0.64226\n"]},{"data":{"text/plain":["(1.9047490358352661, 0.6412797619047619, 0.6422619047619048)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["torch.manual_seed(1337)\n","epochs = 20\n","lr = 0.1\n","model = MLP(n_input, n_hidden, n_output)\n","train(model, X / X.max(), Y, val_x / val_x.max(), val_y, epochs, lr)"]},{"cell_type":"markdown","metadata":{},"source":["Now, it's converging!"]},{"cell_type":"markdown","metadata":{},"source":["# 🧪 Experimenting With HyperParams"]},{"cell_type":"markdown","metadata":{},"source":["### Larger? (More Neurons)"]},{"cell_type":"markdown","metadata":{},"source":["Using larger hidden size"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Hidden Size 10 \t| Training Loss: 1.84777\t| Training Accuracy: 0.57107\t| Validation Accuracy: 0.56524\n","Hidden Size 20 \t| Training Loss: 2.00653\t| Training Accuracy: 0.43057\t| Validation Accuracy: 0.43667\n","Hidden Size 40 \t| Training Loss: 1.85503\t| Training Accuracy: 0.65479\t| Validation Accuracy: 0.65286\n","Hidden Size 80 \t| Training Loss: 1.84987\t| Training Accuracy: 0.66063\t| Validation Accuracy: 0.66452\n"]}],"source":["# Train and evaluate models with different hidden sizes\n","for hidden_size in [10, 20, 40, 80]:\n","    model = MLP(n_input, hidden_size, n_output)\n","    loss, train_acc, val_acc = train(model, X / X.max(), Y, val_x / val_x.max(), val_y, epochs, lr, print_epochs=False)\n","    print(f'Hidden Size {hidden_size} \\t| Training Loss: {loss:.5f}\\t| Training Accuracy: {train_acc:.5f}\\t| Validation Accuracy: {val_acc:.5f}')"]},{"cell_type":"markdown","metadata":{},"source":["### Longer?"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Hidden Size 10 \t| Training Loss: 0.83191\t| Training Accuracy: 0.81711\t| Validation Accuracy: 0.82393\n","Hidden Size 20 \t| Training Loss: 0.61951\t| Training Accuracy: 0.85247\t| Validation Accuracy: 0.85488\n","Hidden Size 40 \t| Training Loss: 0.60518\t| Training Accuracy: 0.85979\t| Validation Accuracy: 0.86226\n","Hidden Size 80 \t| Training Loss: 0.58343\t| Training Accuracy: 0.86185\t| Validation Accuracy: 0.86214\n"]}],"source":["# Train and evaluate models with different hidden sizes\n","for hidden_size in [10, 20, 40, 80]:\n","    model = MLP(n_input, hidden_size, n_output)\n","    loss, train_acc, val_acc = train(model, X / X.max(), Y, val_x / val_x.max(), val_y, 100, lr, print_epochs=False)\n","    print(f'Hidden Size {hidden_size} \\t| Training Loss: {loss:.5f}\\t| Training Accuracy: {train_acc:.5f}\\t| Validation Accuracy: {val_acc:.5f}')"]},{"cell_type":"markdown","metadata":{},"source":["### Deeper?"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Hidden Size 10 \t| Training Loss: 0.95403\t| Training Accuracy: 0.75283\t| Validation Accuracy: 0.74952\n","Hidden Size 20 \t| Training Loss: 0.97217\t| Training Accuracy: 0.74589\t| Validation Accuracy: 0.74798\n","Hidden Size 40 \t| Training Loss: 0.86809\t| Training Accuracy: 0.79923\t| Validation Accuracy: 0.80060\n","Hidden Size 80 \t| Training Loss: 0.74327\t| Training Accuracy: 0.80482\t| Validation Accuracy: 0.80774\n"]}],"source":["class DeepNet(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(DeepNet, self).__init__()\n","        self.layer1 = nn.Linear(input_size, hidden_size)\n","        self.layer2 = nn.Linear(hidden_size, hidden_size)\n","        self.layer3 = nn.Linear(hidden_size, output_size)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.relu(self.layer1(x))\n","        x = self.relu(self.layer2(x))\n","        x = self.layer3(x)\n","        return x\n","\n","# Train and evaluate models with different hidden sizes\n","for hidden_size in [10, 20, 40, 80]:\n","    model = DeepNet(n_input, hidden_size, n_output)\n","    loss, train_acc, val_acc = train(model, X / X.max(), Y, val_x / val_x.max(), val_y, 100, lr, print_epochs=False)\n","    print(f'Hidden Size {hidden_size} \\t| Training Loss: {loss:.5f}\\t| Training Accuracy: {train_acc:.5f}\\t| Validation Accuracy: {val_acc:.5f}')"]},{"cell_type":"markdown","metadata":{},"source":["So having more layers is not necessary better, it depends. Actually adding more layers involves a bit more work in the architecture of the model, but this is beyond the scope of this little tutorial."]},{"cell_type":"markdown","metadata":{},"source":["# 🏎️ Another Optimizer"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-07-03T18:40:20.550134Z","iopub.status.busy":"2024-07-03T18:40:20.549456Z","iopub.status.idle":"2024-07-03T18:41:00.056426Z","shell.execute_reply":"2024-07-03T18:41:00.055328Z","shell.execute_reply.started":"2024-07-03T18:40:20.550099Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Hidden Size 10 \t| Training Loss: 0.32118\t| Training Accuracy: 0.90693\t| Validation Accuracy: 0.89369\n","Hidden Size 20 \t| Training Loss: 0.20290\t| Training Accuracy: 0.94259\t| Validation Accuracy: 0.92524\n","Hidden Size 40 \t| Training Loss: 0.20566\t| Training Accuracy: 0.94354\t| Validation Accuracy: 0.92905\n","Hidden Size 80 \t| Training Loss: 0.28931\t| Training Accuracy: 0.91872\t| Validation Accuracy: 0.90429\n"]}],"source":["def train_with_adamw(model, X, Y, val_x, val_y, epochs, lr, print_epochs=True):\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n","    for epoch in range(epochs):\n","        optimizer.zero_grad()\n","        # Forward\n","        model.train()\n","        logits = model(X)\n","        loss = loss_fn(logits, Y)\n","        # Backward\n","        loss.backward()\n","        # Update parameters\n","        optimizer.step()\n","\n","        # Evaluation\n","        model.eval()\n","        with torch.no_grad():\n","            train_acc = accuracy(model(X), Y)\n","            val_acc = accuracy(model(val_x), val_y)\n","        if print_epochs:\n","            print(f'Epoch {epoch+1} \\t| Training Loss: {loss.item():.5f}\\t| Training Accuracy: {train_acc:.5f}\\t| Validation Accuracy: {val_acc:.5f}')\n","    return loss.item(), train_acc, val_acc\n","\n","# Train and evaluate models with different hidden sizes\n","for hidden_size in [10, 20, 40, 80]:\n","    model = MLP(n_input, hidden_size, n_output)\n","    loss, train_acc, val_acc = train_with_adamw(model, X / X.max(), Y, val_x / val_x.max(), val_y, 100, lr, print_epochs=False)\n","    print(f'Hidden Size {hidden_size} \\t| Training Loss: {loss:.5f}\\t| Training Accuracy: {train_acc:.5f}\\t| Validation Accuracy: {val_acc:.5f}')"]},{"cell_type":"markdown","metadata":{},"source":["(for me) the best model is 40 hidden size + adamw + 100 epochs"]},{"cell_type":"markdown","metadata":{},"source":["> Note: With better techniques you won't have to do 100 epochs."]},{"cell_type":"markdown","metadata":{},"source":["# 👏 Kaggle Submission"]},{"cell_type":"markdown","metadata":{},"source":["### Ensembling"]},{"cell_type":"markdown","metadata":{},"source":["Ensembling = training different models and averaging their predictions"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-07-03T18:41:00.058776Z","iopub.status.busy":"2024-07-03T18:41:00.057887Z","iopub.status.idle":"2024-07-03T18:41:53.299832Z","shell.execute_reply":"2024-07-03T18:41:53.299010Z","shell.execute_reply.started":"2024-07-03T18:41:00.058732Z"},"trusted":true},"outputs":[],"source":["def ensemble(test_x):\n","    model = MLP(n_input, 40, n_output)\n","    train_with_adamw(model, X / X.max(), Y, val_x / val_x.max(), val_y, 100, lr, print_epochs=False)\n","    return model(test_x / test_x.max())\n","\n","# loading test data\n","test_df = pd.read_csv(path/'test.csv')\n","# turn that into pixels\n","test_x = torch.from_numpy(test_df.values).float()\n","# train 5 models\n","learns = [ensemble(test_x) for _ in range(5)]\n","# average their predictions\n","ens_preds = torch.stack(learns).mean(0)"]},{"cell_type":"markdown","metadata":{},"source":["### Kaggle Submission"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-07-03T18:41:53.301191Z","iopub.status.busy":"2024-07-03T18:41:53.300902Z","iopub.status.idle":"2024-07-03T18:41:53.345882Z","shell.execute_reply":"2024-07-03T18:41:53.345098Z","shell.execute_reply.started":"2024-07-03T18:41:53.301167Z"},"trusted":true},"outputs":[],"source":["test_df['ImageId'] = range(1, len(test_df) + 1)\n","test_df['Label'] = torch.argmax(ens_preds, dim=1)\n","sub_df = test_df[['ImageId','Label']]\n","sub_df.to_csv('submission.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["### Thank you! I hope you enjoyed this walkthrough, if so please give it a 👍 thanks!"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":861823,"sourceId":3004,"sourceType":"competition"}],"dockerImageVersionId":30732,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
